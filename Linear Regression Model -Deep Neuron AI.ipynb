{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center> Linear Regression Model -Deep Neuron AI </center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qOvPEYVz2mTX"
   },
   "outputs": [],
   "source": [
    "batch_n = 100\n",
    "in_features = 3\n",
    "out_features = 1\n",
    "epoch_n = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LtyiHg6R3MVx"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t88ZyGuw2yUM",
    "outputId": "69ea76f2-6b83-44d9-936e-5239ad148d5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.8284],\n",
      "        [5.7548],\n",
      "        [5.8606],\n",
      "        [6.5128],\n",
      "        [7.3174],\n",
      "        [3.9792],\n",
      "        [5.3855],\n",
      "        [7.2779],\n",
      "        [2.7207],\n",
      "        [5.6291],\n",
      "        [2.9060],\n",
      "        [5.5433],\n",
      "        [4.6266],\n",
      "        [3.4104],\n",
      "        [6.7947],\n",
      "        [2.5868],\n",
      "        [8.0650],\n",
      "        [5.2113],\n",
      "        [6.7778],\n",
      "        [6.0361],\n",
      "        [5.8022],\n",
      "        [7.2510],\n",
      "        [2.2109],\n",
      "        [7.3034],\n",
      "        [5.4642],\n",
      "        [5.8302],\n",
      "        [5.1825],\n",
      "        [6.6583],\n",
      "        [2.6934],\n",
      "        [7.8369],\n",
      "        [7.5410],\n",
      "        [2.2026],\n",
      "        [6.1026],\n",
      "        [3.7129],\n",
      "        [2.5404],\n",
      "        [5.8276],\n",
      "        [5.9817],\n",
      "        [4.1345],\n",
      "        [4.8721],\n",
      "        [0.9628],\n",
      "        [3.8681],\n",
      "        [1.9798],\n",
      "        [5.3771],\n",
      "        [6.1766],\n",
      "        [6.4796],\n",
      "        [3.7479],\n",
      "        [8.2087],\n",
      "        [3.8948],\n",
      "        [8.8641],\n",
      "        [5.4507],\n",
      "        [2.3621],\n",
      "        [7.1704],\n",
      "        [3.0112],\n",
      "        [6.6898],\n",
      "        [8.2253],\n",
      "        [3.8951],\n",
      "        [2.9011],\n",
      "        [6.2585],\n",
      "        [5.2099],\n",
      "        [7.1893],\n",
      "        [5.9059],\n",
      "        [7.3009],\n",
      "        [5.3225],\n",
      "        [8.6442],\n",
      "        [3.0389],\n",
      "        [8.6146],\n",
      "        [6.3883],\n",
      "        [7.2743],\n",
      "        [4.6916],\n",
      "        [6.9153],\n",
      "        [4.1269],\n",
      "        [6.3512],\n",
      "        [2.6825],\n",
      "        [3.2846],\n",
      "        [2.8792],\n",
      "        [3.5504],\n",
      "        [2.6102],\n",
      "        [6.8402],\n",
      "        [3.8411],\n",
      "        [3.9711],\n",
      "        [3.4156],\n",
      "        [6.7070],\n",
      "        [2.0999],\n",
      "        [7.6439],\n",
      "        [7.4496],\n",
      "        [3.5903],\n",
      "        [7.0061],\n",
      "        [3.0618],\n",
      "        [6.5125],\n",
      "        [4.4688],\n",
      "        [7.0905],\n",
      "        [4.2028],\n",
      "        [6.0806],\n",
      "        [6.8174],\n",
      "        [3.9062],\n",
      "        [2.5433],\n",
      "        [3.0297],\n",
      "        [7.9064],\n",
      "        [5.6946],\n",
      "        [7.4785]])\n"
     ]
    }
   ],
   "source": [
    "# y = 3x_1 + 5x_2 + 1x_3\n",
    "x = torch.rand(batch_n, in_features)\n",
    "c = torch.Tensor([[3.], [5.], [1]])\n",
    "y = x.mm(c)\n",
    "y = y.add(torch.rand(batch_n, out_features))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BwRKxzUw4WLx"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "R6YYOAH24tul",
    "outputId": "027fc10a-a1d7-464c-b7d1-e888f350fdaa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(x[:, 1], y)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5QJDvUet5YvB",
    "outputId": "63c13b85-94f9-4bb8-f440-f37c66832156"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2026],\n",
       "        [0.1980],\n",
       "        [0.9960]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.rand(in_features, out_features)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S2pSnQK16EPr",
    "outputId": "9b4884b2-4633-44ad-d1ec-652ab086b2ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 Loss:2382.1616\n",
      "Epoch:1 Loss:1604.0050\n",
      "Epoch:2 Loss:1089.1847\n",
      "Epoch:3 Loss:748.3018\n",
      "Epoch:4 Loss:522.3165\n",
      "Epoch:5 Loss:372.2390\n",
      "Epoch:6 Loss:272.3196\n",
      "Epoch:7 Loss:205.5524\n",
      "Epoch:8 Loss:160.7059\n",
      "Epoch:9 Loss:130.3621\n",
      "Epoch:10 Loss:109.6211\n",
      "Epoch:11 Loss:95.2463\n",
      "Epoch:12 Loss:85.0993\n",
      "Epoch:13 Loss:77.7672\n",
      "Epoch:14 Loss:72.3161\n",
      "Epoch:15 Loss:68.1282\n",
      "Epoch:16 Loss:64.7952\n",
      "Epoch:17 Loss:62.0465\n",
      "Epoch:18 Loss:59.7026\n",
      "Epoch:19 Loss:57.6444\n",
      "Epoch:20 Loss:55.7927\n",
      "Epoch:21 Loss:54.0943\n",
      "Epoch:22 Loss:52.5138\n",
      "Epoch:23 Loss:51.0269\n",
      "Epoch:24 Loss:49.6171\n",
      "Epoch:25 Loss:48.2732\n",
      "Epoch:26 Loss:46.9869\n",
      "Epoch:27 Loss:45.7524\n",
      "Epoch:28 Loss:44.5655\n",
      "Epoch:29 Loss:43.4227\n",
      "Epoch:30 Loss:42.3215\n",
      "Epoch:31 Loss:41.2596\n",
      "Epoch:32 Loss:40.2352\n",
      "Epoch:33 Loss:39.2465\n",
      "Epoch:34 Loss:38.2923\n",
      "Epoch:35 Loss:37.3711\n",
      "Epoch:36 Loss:36.4816\n",
      "Epoch:37 Loss:35.6227\n",
      "Epoch:38 Loss:34.7933\n",
      "Epoch:39 Loss:33.9922\n",
      "Epoch:40 Loss:33.2186\n",
      "Epoch:41 Loss:32.4715\n",
      "Epoch:42 Loss:31.7498\n",
      "Epoch:43 Loss:31.0527\n",
      "Epoch:44 Loss:30.3793\n",
      "Epoch:45 Loss:29.7288\n",
      "Epoch:46 Loss:29.1005\n",
      "Epoch:47 Loss:28.4935\n",
      "Epoch:48 Loss:27.9070\n",
      "Epoch:49 Loss:27.3405\n",
      "Epoch:50 Loss:26.7931\n",
      "Epoch:51 Loss:26.2642\n",
      "Epoch:52 Loss:25.7533\n",
      "Epoch:53 Loss:25.2595\n",
      "Epoch:54 Loss:24.7825\n",
      "Epoch:55 Loss:24.3215\n",
      "Epoch:56 Loss:23.8760\n",
      "Epoch:57 Loss:23.4456\n",
      "Epoch:58 Loss:23.0296\n",
      "Epoch:59 Loss:22.6275\n",
      "Epoch:60 Loss:22.2390\n",
      "Epoch:61 Loss:21.8635\n",
      "Epoch:62 Loss:21.5005\n",
      "Epoch:63 Loss:21.1498\n",
      "Epoch:64 Loss:20.8107\n",
      "Epoch:65 Loss:20.4830\n",
      "Epoch:66 Loss:20.1662\n",
      "Epoch:67 Loss:19.8600\n",
      "Epoch:68 Loss:19.5640\n",
      "Epoch:69 Loss:19.2778\n",
      "Epoch:70 Loss:19.0012\n",
      "Epoch:71 Loss:18.7338\n",
      "Epoch:72 Loss:18.4752\n",
      "Epoch:73 Loss:18.2252\n",
      "Epoch:74 Loss:17.9835\n",
      "Epoch:75 Loss:17.7499\n",
      "Epoch:76 Loss:17.5239\n",
      "Epoch:77 Loss:17.3054\n",
      "Epoch:78 Loss:17.0942\n",
      "Epoch:79 Loss:16.8899\n",
      "Epoch:80 Loss:16.6923\n",
      "Epoch:81 Loss:16.5013\n",
      "Epoch:82 Loss:16.3165\n",
      "Epoch:83 Loss:16.1379\n",
      "Epoch:84 Loss:15.9651\n",
      "Epoch:85 Loss:15.7980\n",
      "Epoch:86 Loss:15.6363\n",
      "Epoch:87 Loss:15.4800\n",
      "Epoch:88 Loss:15.3288\n",
      "Epoch:89 Loss:15.1825\n",
      "Epoch:90 Loss:15.0410\n",
      "Epoch:91 Loss:14.9042\n",
      "Epoch:92 Loss:14.7718\n",
      "Epoch:93 Loss:14.6437\n",
      "Epoch:94 Loss:14.5199\n",
      "Epoch:95 Loss:14.4000\n",
      "Epoch:96 Loss:14.2841\n",
      "Epoch:97 Loss:14.1719\n",
      "Epoch:98 Loss:14.0633\n",
      "Epoch:99 Loss:13.9583\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch_n):\n",
    "  y_pred = x.mm(w)\n",
    "  loss = (y_pred - y).pow(2).sum() # MSE\n",
    "  print('Epoch:{} Loss:{:.4f}'.format(epoch, loss))\n",
    "\n",
    "  grad_y_pred = 2 * (y_pred - y)\n",
    "  grad_w = x.t().mm(grad_y_pred)\n",
    "  \n",
    "  w -= learning_rate * grad_w "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_roQribv82UJ",
    "outputId": "a181410f-3355-4c09-a72c-47a71bafb924"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.4125],\n",
       "        [4.7137],\n",
       "        [1.7919]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "v3kgdLjQ87Q9"
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Ranqs8PQ9rHQ"
   },
   "outputs": [],
   "source": [
    "Vx = Variable(x, requires_grad=False)\n",
    "Vy = Variable(y, requires_grad=False)\n",
    "Vw = Variable(torch.rand(in_features, out_features), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g87IoqM7-xSk",
    "outputId": "e13e13df-220f-4b28-ff82-865ce314c832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 Loss:2420.7625\n",
      "Epoch:1 Loss:1628.8695\n",
      "Epoch:2 Loss:1104.9900\n",
      "Epoch:3 Loss:758.1367\n",
      "Epoch:4 Loss:528.2206\n",
      "Epoch:5 Loss:375.5591\n",
      "Epoch:6 Loss:273.9450\n",
      "Epoch:7 Loss:206.0702\n",
      "Epoch:8 Loss:160.5038\n",
      "Epoch:9 Loss:129.6959\n",
      "Epoch:10 Loss:108.6596\n",
      "Epoch:11 Loss:94.1008\n",
      "Epoch:12 Loss:83.8432\n",
      "Epoch:13 Loss:76.4488\n",
      "Epoch:14 Loss:70.9670\n",
      "Epoch:15 Loss:66.7693\n",
      "Epoch:16 Loss:63.4401\n",
      "Epoch:17 Loss:60.7039\n",
      "Epoch:18 Loss:58.3782\n",
      "Epoch:19 Loss:56.3419\n",
      "Epoch:20 Loss:54.5141\n",
      "Epoch:21 Loss:52.8411\n",
      "Epoch:22 Loss:51.2864\n",
      "Epoch:23 Loss:49.8258\n",
      "Epoch:24 Loss:48.4423\n",
      "Epoch:25 Loss:47.1245\n",
      "Epoch:26 Loss:45.8641\n",
      "Epoch:27 Loss:44.6552\n",
      "Epoch:28 Loss:43.4934\n",
      "Epoch:29 Loss:42.3754\n",
      "Epoch:30 Loss:41.2985\n",
      "Epoch:31 Loss:40.2605\n",
      "Epoch:32 Loss:39.2595\n",
      "Epoch:33 Loss:38.2939\n",
      "Epoch:34 Loss:37.3622\n",
      "Epoch:35 Loss:36.4631\n",
      "Epoch:36 Loss:35.5953\n",
      "Epoch:37 Loss:34.7577\n",
      "Epoch:38 Loss:33.9491\n",
      "Epoch:39 Loss:33.1684\n",
      "Epoch:40 Loss:32.4148\n",
      "Epoch:41 Loss:31.6871\n",
      "Epoch:42 Loss:30.9846\n",
      "Epoch:43 Loss:30.3062\n",
      "Epoch:44 Loss:29.6512\n",
      "Epoch:45 Loss:29.0186\n",
      "Epoch:46 Loss:28.4078\n",
      "Epoch:47 Loss:27.8180\n",
      "Epoch:48 Loss:27.2483\n",
      "Epoch:49 Loss:26.6982\n",
      "Epoch:50 Loss:26.1668\n",
      "Epoch:51 Loss:25.6537\n",
      "Epoch:52 Loss:25.1580\n",
      "Epoch:53 Loss:24.6793\n",
      "Epoch:54 Loss:24.2168\n",
      "Epoch:55 Loss:23.7702\n",
      "Epoch:56 Loss:23.3387\n",
      "Epoch:57 Loss:22.9219\n",
      "Epoch:58 Loss:22.5192\n",
      "Epoch:59 Loss:22.1302\n",
      "Epoch:60 Loss:21.7544\n",
      "Epoch:61 Loss:21.3913\n",
      "Epoch:62 Loss:21.0405\n",
      "Epoch:63 Loss:20.7016\n",
      "Epoch:64 Loss:20.3741\n",
      "Epoch:65 Loss:20.0576\n",
      "Epoch:66 Loss:19.7519\n",
      "Epoch:67 Loss:19.4564\n",
      "Epoch:68 Loss:19.1709\n",
      "Epoch:69 Loss:18.8950\n",
      "Epoch:70 Loss:18.6283\n",
      "Epoch:71 Loss:18.3706\n",
      "Epoch:72 Loss:18.1216\n",
      "Epoch:73 Loss:17.8809\n",
      "Epoch:74 Loss:17.6482\n",
      "Epoch:75 Loss:17.4234\n",
      "Epoch:76 Loss:17.2060\n",
      "Epoch:77 Loss:16.9959\n",
      "Epoch:78 Loss:16.7928\n",
      "Epoch:79 Loss:16.5965\n",
      "Epoch:80 Loss:16.4067\n",
      "Epoch:81 Loss:16.2233\n",
      "Epoch:82 Loss:16.0459\n",
      "Epoch:83 Loss:15.8745\n",
      "Epoch:84 Loss:15.7087\n",
      "Epoch:85 Loss:15.5484\n",
      "Epoch:86 Loss:15.3935\n",
      "Epoch:87 Loss:15.2436\n",
      "Epoch:88 Loss:15.0987\n",
      "Epoch:89 Loss:14.9587\n",
      "Epoch:90 Loss:14.8232\n",
      "Epoch:91 Loss:14.6922\n",
      "Epoch:92 Loss:14.5655\n",
      "Epoch:93 Loss:14.4430\n",
      "Epoch:94 Loss:14.3245\n",
      "Epoch:95 Loss:14.2100\n",
      "Epoch:96 Loss:14.0992\n",
      "Epoch:97 Loss:13.9920\n",
      "Epoch:98 Loss:13.8883\n",
      "Epoch:99 Loss:13.7881\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch_n):\n",
    "  y_pred = Vx.mm(Vw)\n",
    "  loss = (y_pred - Vy).pow(2).sum() # MSE\n",
    "  print('Epoch:{} Loss:{:.4f}'.format(epoch, loss))\n",
    "\n",
    "  loss.backward()\n",
    "  \n",
    "  Vw.data -= learning_rate * Vw.grad.data\n",
    "\n",
    "  Vw.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qeb1op-j_s_2",
    "outputId": "aa7f8837-1e10-4220-e61b-5f24f74bc3d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.3979],\n",
       "        [4.7329],\n",
       "        [1.7871]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vw.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8YyWYYlUjZsT"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "EO6yQ4mpjgvD"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Model, self).__init__()\n",
    "  \n",
    "  def forward(self, x, w):\n",
    "    y_pred = x.mm(w)\n",
    "    return y_pred\n",
    "  \n",
    "  def backward(self):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "UaZrSetAtqdW"
   },
   "outputs": [],
   "source": [
    "model = Model()\n",
    "Vw = Variable(torch.rand(in_features, out_features), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y_FX6h3ytu6i",
    "outputId": "6ce317d5-13f4-464c-8849-00df62c5e741"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 Loss:2368.3599\n",
      "Epoch:1 Loss:1586.1260\n",
      "Epoch:2 Loss:1068.9242\n",
      "Epoch:3 Loss:726.7683\n",
      "Epoch:4 Loss:500.2314\n",
      "Epoch:5 Loss:350.0682\n",
      "Epoch:6 Loss:250.3606\n",
      "Epoch:7 Loss:183.9919\n",
      "Epoch:8 Loss:139.6581\n",
      "Epoch:9 Loss:109.8931\n",
      "Epoch:10 Loss:89.7660\n",
      "Epoch:11 Loss:76.0199\n",
      "Epoch:12 Loss:66.5034\n",
      "Epoch:13 Loss:59.7951\n",
      "Epoch:14 Loss:54.9559\n",
      "Epoch:15 Loss:51.3650\n",
      "Epoch:16 Loss:48.6121\n",
      "Epoch:17 Loss:46.4256\n",
      "Epoch:18 Loss:44.6258\n",
      "Epoch:19 Loss:43.0935\n",
      "Epoch:20 Loss:41.7497\n",
      "Epoch:21 Loss:40.5416\n",
      "Epoch:22 Loss:39.4341\n",
      "Epoch:23 Loss:38.4036\n",
      "Epoch:24 Loss:37.4341\n",
      "Epoch:25 Loss:36.5147\n",
      "Epoch:26 Loss:35.6379\n",
      "Epoch:27 Loss:34.7984\n",
      "Epoch:28 Loss:33.9924\n",
      "Epoch:29 Loss:33.2169\n",
      "Epoch:30 Loss:32.4699\n",
      "Epoch:31 Loss:31.7497\n",
      "Epoch:32 Loss:31.0548\n",
      "Epoch:33 Loss:30.3840\n",
      "Epoch:34 Loss:29.7363\n",
      "Epoch:35 Loss:29.1108\n",
      "Epoch:36 Loss:28.5065\n",
      "Epoch:37 Loss:27.9227\n",
      "Epoch:38 Loss:27.3587\n",
      "Epoch:39 Loss:26.8137\n",
      "Epoch:40 Loss:26.2871\n",
      "Epoch:41 Loss:25.7782\n",
      "Epoch:42 Loss:25.2864\n",
      "Epoch:43 Loss:24.8110\n",
      "Epoch:44 Loss:24.3517\n",
      "Epoch:45 Loss:23.9077\n",
      "Epoch:46 Loss:23.4785\n",
      "Epoch:47 Loss:23.0637\n",
      "Epoch:48 Loss:22.6628\n",
      "Epoch:49 Loss:22.2752\n",
      "Epoch:50 Loss:21.9006\n",
      "Epoch:51 Loss:21.5384\n",
      "Epoch:52 Loss:21.1883\n",
      "Epoch:53 Loss:20.8498\n",
      "Epoch:54 Loss:20.5226\n",
      "Epoch:55 Loss:20.2062\n",
      "Epoch:56 Loss:19.9003\n",
      "Epoch:57 Loss:19.6046\n",
      "Epoch:58 Loss:19.3186\n",
      "Epoch:59 Loss:19.0421\n",
      "Epoch:60 Loss:18.7748\n",
      "Epoch:61 Loss:18.5162\n",
      "Epoch:62 Loss:18.2662\n",
      "Epoch:63 Loss:18.0245\n",
      "Epoch:64 Loss:17.7907\n",
      "Epoch:65 Loss:17.5646\n",
      "Epoch:66 Loss:17.3459\n",
      "Epoch:67 Loss:17.1344\n",
      "Epoch:68 Loss:16.9299\n",
      "Epoch:69 Loss:16.7320\n",
      "Epoch:70 Loss:16.5407\n",
      "Epoch:71 Loss:16.3556\n",
      "Epoch:72 Loss:16.1766\n",
      "Epoch:73 Loss:16.0034\n",
      "Epoch:74 Loss:15.8359\n",
      "Epoch:75 Loss:15.6738\n",
      "Epoch:76 Loss:15.5170\n",
      "Epoch:77 Loss:15.3654\n",
      "Epoch:78 Loss:15.2187\n",
      "Epoch:79 Loss:15.0767\n",
      "Epoch:80 Loss:14.9394\n",
      "Epoch:81 Loss:14.8065\n",
      "Epoch:82 Loss:14.6779\n",
      "Epoch:83 Loss:14.5535\n",
      "Epoch:84 Loss:14.4332\n",
      "Epoch:85 Loss:14.3167\n",
      "Epoch:86 Loss:14.2040\n",
      "Epoch:87 Loss:14.0950\n",
      "Epoch:88 Loss:13.9894\n",
      "Epoch:89 Loss:13.8873\n",
      "Epoch:90 Loss:13.7885\n",
      "Epoch:91 Loss:13.6928\n",
      "Epoch:92 Loss:13.6003\n",
      "Epoch:93 Loss:13.5107\n",
      "Epoch:94 Loss:13.4240\n",
      "Epoch:95 Loss:13.3401\n",
      "Epoch:96 Loss:13.2589\n",
      "Epoch:97 Loss:13.1802\n",
      "Epoch:98 Loss:13.1041\n",
      "Epoch:99 Loss:13.0305\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch_n):\n",
    "  y_pred = model(Vx, Vw)\n",
    "  loss = (y_pred - Vy).pow(2).sum() # MSE\n",
    "  print('Epoch:{} Loss:{:.4f}'.format(epoch, loss))\n",
    "\n",
    "  loss.backward()\n",
    "  \n",
    "  Vw.data -= learning_rate * Vw.grad.data\n",
    "\n",
    "  Vw.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0p63IaTauEYe",
    "outputId": "331d47f4-0ac9-4c12-bbe5-c81260ba8660"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.4171],\n",
       "        [4.7804],\n",
       "        [1.7195]], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "b2SMGKpkuOta"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Model, self).__init__()\n",
    "    self.linear = nn.Linear(in_features, out_features, False)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    y_pred = self.linear(x)\n",
    "    return y_pred\n",
    "  \n",
    "  def backward(self):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qj7gdUF7sWSD",
    "outputId": "4cd519c6-9f6f-4648-bf0d-024ee101693c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (linear): Linear(in_features=3, out_features=1, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "loss_fn = nn.MSELoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s6_DA5S2spKf",
    "outputId": "1852f918-64e8-4b37-c211-2423efab668e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:99 Loss:21.7634\n",
      "Epoch:199 Loss:15.0964\n",
      "Epoch:299 Loss:10.5109\n",
      "Epoch:399 Loss:7.3560\n",
      "Epoch:499 Loss:5.1844\n",
      "Epoch:599 Loss:3.6887\n",
      "Epoch:699 Loss:2.6577\n",
      "Epoch:799 Loss:1.9460\n",
      "Epoch:899 Loss:1.4540\n",
      "Epoch:999 Loss:1.1130\n",
      "Epoch:1099 Loss:0.8760\n",
      "Epoch:1199 Loss:0.7104\n",
      "Epoch:1299 Loss:0.5941\n",
      "Epoch:1399 Loss:0.5116\n",
      "Epoch:1499 Loss:0.4526\n",
      "Epoch:1599 Loss:0.4098\n",
      "Epoch:1699 Loss:0.3781\n",
      "Epoch:1799 Loss:0.3542\n",
      "Epoch:1899 Loss:0.3357\n",
      "Epoch:1999 Loss:0.3210\n",
      "Epoch:2099 Loss:0.3090\n",
      "Epoch:2199 Loss:0.2989\n",
      "Epoch:2299 Loss:0.2901\n",
      "Epoch:2399 Loss:0.2824\n",
      "Epoch:2499 Loss:0.2754\n",
      "Epoch:2599 Loss:0.2690\n",
      "Epoch:2699 Loss:0.2630\n",
      "Epoch:2799 Loss:0.2574\n",
      "Epoch:2899 Loss:0.2521\n",
      "Epoch:2999 Loss:0.2471\n",
      "Epoch:3099 Loss:0.2423\n",
      "Epoch:3199 Loss:0.2377\n",
      "Epoch:3299 Loss:0.2333\n",
      "Epoch:3399 Loss:0.2290\n",
      "Epoch:3499 Loss:0.2249\n",
      "Epoch:3599 Loss:0.2209\n",
      "Epoch:3699 Loss:0.2171\n",
      "Epoch:3799 Loss:0.2135\n",
      "Epoch:3899 Loss:0.2099\n",
      "Epoch:3999 Loss:0.2065\n",
      "Epoch:4099 Loss:0.2032\n",
      "Epoch:4199 Loss:0.2000\n",
      "Epoch:4299 Loss:0.1969\n",
      "Epoch:4399 Loss:0.1939\n",
      "Epoch:4499 Loss:0.1910\n",
      "Epoch:4599 Loss:0.1883\n",
      "Epoch:4699 Loss:0.1856\n",
      "Epoch:4799 Loss:0.1830\n",
      "Epoch:4899 Loss:0.1805\n",
      "Epoch:4999 Loss:0.1781\n",
      "Epoch:5099 Loss:0.1757\n",
      "Epoch:5199 Loss:0.1735\n",
      "Epoch:5299 Loss:0.1713\n",
      "Epoch:5399 Loss:0.1692\n",
      "Epoch:5499 Loss:0.1672\n",
      "Epoch:5599 Loss:0.1652\n",
      "Epoch:5699 Loss:0.1633\n",
      "Epoch:5799 Loss:0.1615\n",
      "Epoch:5899 Loss:0.1597\n",
      "Epoch:5999 Loss:0.1580\n",
      "Epoch:6099 Loss:0.1563\n",
      "Epoch:6199 Loss:0.1547\n",
      "Epoch:6299 Loss:0.1532\n",
      "Epoch:6399 Loss:0.1517\n",
      "Epoch:6499 Loss:0.1502\n",
      "Epoch:6599 Loss:0.1489\n",
      "Epoch:6699 Loss:0.1475\n",
      "Epoch:6799 Loss:0.1462\n",
      "Epoch:6899 Loss:0.1449\n",
      "Epoch:6999 Loss:0.1437\n",
      "Epoch:7099 Loss:0.1425\n",
      "Epoch:7199 Loss:0.1414\n",
      "Epoch:7299 Loss:0.1403\n",
      "Epoch:7399 Loss:0.1392\n",
      "Epoch:7499 Loss:0.1382\n",
      "Epoch:7599 Loss:0.1372\n",
      "Epoch:7699 Loss:0.1363\n",
      "Epoch:7799 Loss:0.1353\n",
      "Epoch:7899 Loss:0.1344\n",
      "Epoch:7999 Loss:0.1336\n",
      "Epoch:8099 Loss:0.1327\n",
      "Epoch:8199 Loss:0.1319\n",
      "Epoch:8299 Loss:0.1311\n",
      "Epoch:8399 Loss:0.1304\n",
      "Epoch:8499 Loss:0.1296\n",
      "Epoch:8599 Loss:0.1289\n",
      "Epoch:8699 Loss:0.1282\n",
      "Epoch:8799 Loss:0.1276\n",
      "Epoch:8899 Loss:0.1269\n",
      "Epoch:8999 Loss:0.1263\n",
      "Epoch:9099 Loss:0.1257\n",
      "Epoch:9199 Loss:0.1251\n",
      "Epoch:9299 Loss:0.1246\n",
      "Epoch:9399 Loss:0.1240\n",
      "Epoch:9499 Loss:0.1235\n",
      "Epoch:9599 Loss:0.1230\n",
      "Epoch:9699 Loss:0.1225\n",
      "Epoch:9799 Loss:0.1220\n",
      "Epoch:9899 Loss:0.1216\n",
      "Epoch:9999 Loss:0.1211\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch_n*100):\n",
    "  y_pred = model(x)\n",
    "  loss = loss_fn(y_pred, y)\n",
    "  if (epoch + 1) % 100 == 0 :\n",
    "    print('Epoch:{} Loss:{:.4f}'.format(epoch, loss))\n",
    "\n",
    "  model.zero_grad()\n",
    "  loss.backward()\n",
    "  \n",
    "  for parameter in model.parameters():\n",
    "    parameter.data -= learning_rate * parameter.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CAX-a00Tzqr2",
    "outputId": "b078098d-3904-4578-b678-c69897cb3cb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.3759, 4.8802, 1.6599]])\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.parameters():\n",
    "  print(parameter.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "WPiDwDlj3Vnm"
   },
   "outputs": [],
   "source": [
    " model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "nJycQEUT5t5H"
   },
   "outputs": [],
   "source": [
    "import torch.optim as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "78XjD1OF5348"
   },
   "outputs": [],
   "source": [
    "optimizer = opt.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "eYUkoQl26r3n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:99 Loss:23.8711\n",
      "Epoch:199 Loss:16.5974\n",
      "Epoch:299 Loss:11.5932\n",
      "Epoch:399 Loss:8.1490\n",
      "Epoch:499 Loss:5.7770\n",
      "Epoch:599 Loss:4.1420\n",
      "Epoch:699 Loss:3.0138\n",
      "Epoch:799 Loss:2.2339\n",
      "Epoch:899 Loss:1.6937\n",
      "Epoch:999 Loss:1.3182\n",
      "Epoch:1099 Loss:1.0561\n",
      "Epoch:1199 Loss:0.8722\n",
      "Epoch:1299 Loss:0.7419\n",
      "Epoch:1399 Loss:0.6488\n",
      "Epoch:1499 Loss:0.5813\n",
      "Epoch:1599 Loss:0.5316\n",
      "Epoch:1699 Loss:0.4941\n",
      "Epoch:1799 Loss:0.4652\n",
      "Epoch:1899 Loss:0.4422\n",
      "Epoch:1999 Loss:0.4235\n",
      "Epoch:2099 Loss:0.4078\n",
      "Epoch:2199 Loss:0.3943\n",
      "Epoch:2299 Loss:0.3823\n",
      "Epoch:2399 Loss:0.3715\n",
      "Epoch:2499 Loss:0.3616\n",
      "Epoch:2599 Loss:0.3524\n",
      "Epoch:2699 Loss:0.3438\n",
      "Epoch:2799 Loss:0.3356\n",
      "Epoch:2899 Loss:0.3279\n",
      "Epoch:2999 Loss:0.3204\n",
      "Epoch:3099 Loss:0.3133\n",
      "Epoch:3199 Loss:0.3064\n",
      "Epoch:3299 Loss:0.2999\n",
      "Epoch:3399 Loss:0.2935\n",
      "Epoch:3499 Loss:0.2874\n",
      "Epoch:3599 Loss:0.2815\n",
      "Epoch:3699 Loss:0.2758\n",
      "Epoch:3799 Loss:0.2702\n",
      "Epoch:3899 Loss:0.2649\n",
      "Epoch:3999 Loss:0.2598\n",
      "Epoch:4099 Loss:0.2548\n",
      "Epoch:4199 Loss:0.2500\n",
      "Epoch:4299 Loss:0.2454\n",
      "Epoch:4399 Loss:0.2409\n",
      "Epoch:4499 Loss:0.2365\n",
      "Epoch:4599 Loss:0.2323\n",
      "Epoch:4699 Loss:0.2283\n",
      "Epoch:4799 Loss:0.2244\n",
      "Epoch:4899 Loss:0.2206\n",
      "Epoch:4999 Loss:0.2169\n",
      "Epoch:5099 Loss:0.2134\n",
      "Epoch:5199 Loss:0.2100\n",
      "Epoch:5299 Loss:0.2066\n",
      "Epoch:5399 Loss:0.2034\n",
      "Epoch:5499 Loss:0.2003\n",
      "Epoch:5599 Loss:0.1974\n",
      "Epoch:5699 Loss:0.1945\n",
      "Epoch:5799 Loss:0.1917\n",
      "Epoch:5899 Loss:0.1890\n",
      "Epoch:5999 Loss:0.1863\n",
      "Epoch:6099 Loss:0.1838\n",
      "Epoch:6199 Loss:0.1814\n",
      "Epoch:6299 Loss:0.1790\n",
      "Epoch:6399 Loss:0.1767\n",
      "Epoch:6499 Loss:0.1745\n",
      "Epoch:6599 Loss:0.1724\n",
      "Epoch:6699 Loss:0.1703\n",
      "Epoch:6799 Loss:0.1683\n",
      "Epoch:6899 Loss:0.1663\n",
      "Epoch:6999 Loss:0.1645\n",
      "Epoch:7099 Loss:0.1626\n",
      "Epoch:7199 Loss:0.1609\n",
      "Epoch:7299 Loss:0.1592\n",
      "Epoch:7399 Loss:0.1576\n",
      "Epoch:7499 Loss:0.1560\n",
      "Epoch:7599 Loss:0.1544\n",
      "Epoch:7699 Loss:0.1529\n",
      "Epoch:7799 Loss:0.1515\n",
      "Epoch:7899 Loss:0.1501\n",
      "Epoch:7999 Loss:0.1488\n",
      "Epoch:8099 Loss:0.1475\n",
      "Epoch:8199 Loss:0.1462\n",
      "Epoch:8299 Loss:0.1450\n",
      "Epoch:8399 Loss:0.1438\n",
      "Epoch:8499 Loss:0.1426\n",
      "Epoch:8599 Loss:0.1415\n",
      "Epoch:8699 Loss:0.1405\n",
      "Epoch:8799 Loss:0.1394\n",
      "Epoch:8899 Loss:0.1384\n",
      "Epoch:8999 Loss:0.1375\n",
      "Epoch:9099 Loss:0.1365\n",
      "Epoch:9199 Loss:0.1356\n",
      "Epoch:9299 Loss:0.1347\n",
      "Epoch:9399 Loss:0.1339\n",
      "Epoch:9499 Loss:0.1331\n",
      "Epoch:9599 Loss:0.1323\n",
      "Epoch:9699 Loss:0.1315\n",
      "Epoch:9799 Loss:0.1307\n",
      "Epoch:9899 Loss:0.1300\n",
      "Epoch:9999 Loss:0.1293\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch_n*100):\n",
    "  y_pred = model(x)\n",
    "  loss = loss_fn(y_pred, y)\n",
    "  if (epoch + 1) % 100 == 0 :\n",
    "    print('Epoch:{} Loss:{:.4f}'.format(epoch, loss))\n",
    "\n",
    "  model.zero_grad()\n",
    "  loss.backward()\n",
    "  \n",
    "  optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZcYtFDGI68H_",
    "outputId": "87bd44c9-8717-4b26-a9d9-9b49a767266c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.4109, 4.7857, 1.7204]])\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.parameters():\n",
    "  print(parameter.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "oP2huU-T8bHy"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uM1l0WDa8t7q",
    "outputId": "bea0b750-546c-40e4-d010-3ab2f8dd40da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "npy = y.numpy()\n",
    "bins = np.array([npy.mean()])\n",
    "idx = np.digitize(npy, bins)\n",
    "cy = torch.from_numpy(idx)\n",
    "cy = cy.float()\n",
    "print(cy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "MulCIXlR9Y6t"
   },
   "outputs": [],
   "source": [
    "Vx = Variable(x, requires_grad=False)\n",
    "Vy = Variable(cy, requires_grad=False)\n",
    "Vw = Variable(torch.rand(in_features, out_features), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OLUyvRlS-C0R",
    "outputId": "330c1932-650a-48b7-a359-181000baec60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:999 Loss:0.2732\n",
      "Epoch:1999 Loss:0.2714\n",
      "Epoch:2999 Loss:0.2697\n",
      "Epoch:3999 Loss:0.2681\n",
      "Epoch:4999 Loss:0.2667\n",
      "Epoch:5999 Loss:0.2653\n",
      "Epoch:6999 Loss:0.2641\n",
      "Epoch:7999 Loss:0.2629\n",
      "Epoch:8999 Loss:0.2617\n",
      "Epoch:9999 Loss:0.2606\n",
      "Epoch:10999 Loss:0.2596\n",
      "Epoch:11999 Loss:0.2586\n",
      "Epoch:12999 Loss:0.2576\n",
      "Epoch:13999 Loss:0.2567\n",
      "Epoch:14999 Loss:0.2557\n",
      "Epoch:15999 Loss:0.2549\n",
      "Epoch:16999 Loss:0.2540\n",
      "Epoch:17999 Loss:0.2532\n",
      "Epoch:18999 Loss:0.2523\n",
      "Epoch:19999 Loss:0.2515\n",
      "Epoch:20999 Loss:0.2507\n",
      "Epoch:21999 Loss:0.2500\n",
      "Epoch:22999 Loss:0.2492\n",
      "Epoch:23999 Loss:0.2485\n",
      "Epoch:24999 Loss:0.2477\n",
      "Epoch:25999 Loss:0.2470\n",
      "Epoch:26999 Loss:0.2463\n",
      "Epoch:27999 Loss:0.2456\n",
      "Epoch:28999 Loss:0.2450\n",
      "Epoch:29999 Loss:0.2443\n",
      "Epoch:30999 Loss:0.2436\n",
      "Epoch:31999 Loss:0.2430\n",
      "Epoch:32999 Loss:0.2424\n",
      "Epoch:33999 Loss:0.2417\n",
      "Epoch:34999 Loss:0.2411\n",
      "Epoch:35999 Loss:0.2405\n",
      "Epoch:36999 Loss:0.2399\n",
      "Epoch:37999 Loss:0.2393\n",
      "Epoch:38999 Loss:0.2388\n",
      "Epoch:39999 Loss:0.2382\n",
      "Epoch:40999 Loss:0.2376\n",
      "Epoch:41999 Loss:0.2371\n",
      "Epoch:42999 Loss:0.2365\n",
      "Epoch:43999 Loss:0.2360\n",
      "Epoch:44999 Loss:0.2355\n",
      "Epoch:45999 Loss:0.2350\n",
      "Epoch:46999 Loss:0.2344\n",
      "Epoch:47999 Loss:0.2339\n",
      "Epoch:48999 Loss:0.2334\n",
      "Epoch:49999 Loss:0.2330\n",
      "Epoch:50999 Loss:0.2325\n",
      "Epoch:51999 Loss:0.2320\n",
      "Epoch:52999 Loss:0.2315\n",
      "Epoch:53999 Loss:0.2311\n",
      "Epoch:54999 Loss:0.2306\n",
      "Epoch:55999 Loss:0.2302\n",
      "Epoch:56999 Loss:0.2297\n",
      "Epoch:57999 Loss:0.2293\n",
      "Epoch:58999 Loss:0.2289\n",
      "Epoch:59999 Loss:0.2284\n",
      "Epoch:60999 Loss:0.2280\n",
      "Epoch:61999 Loss:0.2276\n",
      "Epoch:62999 Loss:0.2272\n",
      "Epoch:63999 Loss:0.2268\n",
      "Epoch:64999 Loss:0.2264\n",
      "Epoch:65999 Loss:0.2260\n",
      "Epoch:66999 Loss:0.2256\n",
      "Epoch:67999 Loss:0.2253\n",
      "Epoch:68999 Loss:0.2249\n",
      "Epoch:69999 Loss:0.2245\n",
      "Epoch:70999 Loss:0.2242\n",
      "Epoch:71999 Loss:0.2238\n",
      "Epoch:72999 Loss:0.2235\n",
      "Epoch:73999 Loss:0.2231\n",
      "Epoch:74999 Loss:0.2228\n",
      "Epoch:75999 Loss:0.2224\n",
      "Epoch:76999 Loss:0.2221\n",
      "Epoch:77999 Loss:0.2218\n",
      "Epoch:78999 Loss:0.2214\n",
      "Epoch:79999 Loss:0.2211\n",
      "Epoch:80999 Loss:0.2208\n",
      "Epoch:81999 Loss:0.2205\n",
      "Epoch:82999 Loss:0.2202\n",
      "Epoch:83999 Loss:0.2199\n",
      "Epoch:84999 Loss:0.2196\n",
      "Epoch:85999 Loss:0.2193\n",
      "Epoch:86999 Loss:0.2190\n",
      "Epoch:87999 Loss:0.2187\n",
      "Epoch:88999 Loss:0.2184\n",
      "Epoch:89999 Loss:0.2181\n",
      "Epoch:90999 Loss:0.2179\n",
      "Epoch:91999 Loss:0.2176\n",
      "Epoch:92999 Loss:0.2173\n",
      "Epoch:93999 Loss:0.2171\n",
      "Epoch:94999 Loss:0.2168\n",
      "Epoch:95999 Loss:0.2165\n",
      "Epoch:96999 Loss:0.2163\n",
      "Epoch:97999 Loss:0.2160\n",
      "Epoch:98999 Loss:0.2158\n",
      "Epoch:99999 Loss:0.2155\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch_n*1000):\n",
    "  y_pred = torch.sigmoid(Vx.mm(Vw))\n",
    "  loss = (-1.0*(\n",
    "              Vy*torch.log10(y_pred) + (1.0-Vy) * torch.log10(1.0-y_pred)\n",
    "          )).mean()\n",
    "  if (epoch + 1)%1000 == 0:\n",
    "    print('Epoch:{} Loss:{:.4f}'.format(epoch, loss))\n",
    "\n",
    "  loss.backward()\n",
    "  \n",
    "  Vw.data -= learning_rate * Vw.grad.data\n",
    "\n",
    "  Vw.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o7yoIwl6_Wp9",
    "outputId": "baec0379-f1a2-402f-a05d-ff2d1dbf7f62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3253],\n",
       "        [ 2.2471],\n",
       "        [-1.1310]], requires_grad=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "NTkB985n_a-N"
   },
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(LogisticRegression, self).__init__()\n",
    "   \n",
    "  def forward(self, x, w):\n",
    "    y_pred = torch.sigmoid(x.mm(w))\n",
    "    return y_pred\n",
    "  \n",
    "  def backward(self):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "hIX61-HEARe1"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "Vw = torch.rand(in_features, out_features, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "zOgQ3jveAexY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:999 Loss:0.2881\n",
      "Epoch:1999 Loss:0.2848\n",
      "Epoch:2999 Loss:0.2818\n",
      "Epoch:3999 Loss:0.2790\n",
      "Epoch:4999 Loss:0.2765\n",
      "Epoch:5999 Loss:0.2741\n",
      "Epoch:6999 Loss:0.2720\n",
      "Epoch:7999 Loss:0.2700\n",
      "Epoch:8999 Loss:0.2681\n",
      "Epoch:9999 Loss:0.2664\n",
      "Epoch:10999 Loss:0.2648\n",
      "Epoch:11999 Loss:0.2633\n",
      "Epoch:12999 Loss:0.2619\n",
      "Epoch:13999 Loss:0.2606\n",
      "Epoch:14999 Loss:0.2593\n",
      "Epoch:15999 Loss:0.2582\n",
      "Epoch:16999 Loss:0.2570\n",
      "Epoch:17999 Loss:0.2560\n",
      "Epoch:18999 Loss:0.2550\n",
      "Epoch:19999 Loss:0.2540\n",
      "Epoch:20999 Loss:0.2531\n",
      "Epoch:21999 Loss:0.2522\n",
      "Epoch:22999 Loss:0.2513\n",
      "Epoch:23999 Loss:0.2505\n",
      "Epoch:24999 Loss:0.2496\n",
      "Epoch:25999 Loss:0.2489\n",
      "Epoch:26999 Loss:0.2481\n",
      "Epoch:27999 Loss:0.2473\n",
      "Epoch:28999 Loss:0.2466\n",
      "Epoch:29999 Loss:0.2459\n",
      "Epoch:30999 Loss:0.2452\n",
      "Epoch:31999 Loss:0.2445\n",
      "Epoch:32999 Loss:0.2439\n",
      "Epoch:33999 Loss:0.2432\n",
      "Epoch:34999 Loss:0.2426\n",
      "Epoch:35999 Loss:0.2419\n",
      "Epoch:36999 Loss:0.2413\n",
      "Epoch:37999 Loss:0.2407\n",
      "Epoch:38999 Loss:0.2401\n",
      "Epoch:39999 Loss:0.2395\n",
      "Epoch:40999 Loss:0.2389\n",
      "Epoch:41999 Loss:0.2384\n",
      "Epoch:42999 Loss:0.2378\n",
      "Epoch:43999 Loss:0.2373\n",
      "Epoch:44999 Loss:0.2367\n",
      "Epoch:45999 Loss:0.2362\n",
      "Epoch:46999 Loss:0.2357\n",
      "Epoch:47999 Loss:0.2351\n",
      "Epoch:48999 Loss:0.2346\n",
      "Epoch:49999 Loss:0.2341\n",
      "Epoch:50999 Loss:0.2336\n",
      "Epoch:51999 Loss:0.2332\n",
      "Epoch:52999 Loss:0.2327\n",
      "Epoch:53999 Loss:0.2322\n",
      "Epoch:54999 Loss:0.2317\n",
      "Epoch:55999 Loss:0.2313\n",
      "Epoch:56999 Loss:0.2308\n",
      "Epoch:57999 Loss:0.2304\n",
      "Epoch:58999 Loss:0.2299\n",
      "Epoch:59999 Loss:0.2295\n",
      "Epoch:60999 Loss:0.2291\n",
      "Epoch:61999 Loss:0.2287\n",
      "Epoch:62999 Loss:0.2282\n",
      "Epoch:63999 Loss:0.2278\n",
      "Epoch:64999 Loss:0.2274\n",
      "Epoch:65999 Loss:0.2270\n",
      "Epoch:66999 Loss:0.2266\n",
      "Epoch:67999 Loss:0.2263\n",
      "Epoch:68999 Loss:0.2259\n",
      "Epoch:69999 Loss:0.2255\n",
      "Epoch:70999 Loss:0.2251\n",
      "Epoch:71999 Loss:0.2248\n",
      "Epoch:72999 Loss:0.2244\n",
      "Epoch:73999 Loss:0.2240\n",
      "Epoch:74999 Loss:0.2237\n",
      "Epoch:75999 Loss:0.2233\n",
      "Epoch:76999 Loss:0.2230\n",
      "Epoch:77999 Loss:0.2227\n",
      "Epoch:78999 Loss:0.2223\n",
      "Epoch:79999 Loss:0.2220\n",
      "Epoch:80999 Loss:0.2217\n",
      "Epoch:81999 Loss:0.2214\n",
      "Epoch:82999 Loss:0.2210\n",
      "Epoch:83999 Loss:0.2207\n",
      "Epoch:84999 Loss:0.2204\n",
      "Epoch:85999 Loss:0.2201\n",
      "Epoch:86999 Loss:0.2198\n",
      "Epoch:87999 Loss:0.2195\n",
      "Epoch:88999 Loss:0.2192\n",
      "Epoch:89999 Loss:0.2190\n",
      "Epoch:90999 Loss:0.2187\n",
      "Epoch:91999 Loss:0.2184\n",
      "Epoch:92999 Loss:0.2181\n",
      "Epoch:93999 Loss:0.2178\n",
      "Epoch:94999 Loss:0.2176\n",
      "Epoch:95999 Loss:0.2173\n",
      "Epoch:96999 Loss:0.2170\n",
      "Epoch:97999 Loss:0.2168\n",
      "Epoch:98999 Loss:0.2165\n",
      "Epoch:99999 Loss:0.2163\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch_n*1000):\n",
    "  y_pred = model(Vx, Vw)\n",
    "  loss = (-1.0*(\n",
    "              Vy*torch.log10(y_pred) + (1.0-Vy) * torch.log10(1.0-y_pred)\n",
    "          )).mean()\n",
    "  if (epoch + 1)%1000 == 0:\n",
    "    print('Epoch:{} Loss:{:.4f}'.format(epoch, loss))\n",
    "\n",
    "  loss.backward()\n",
    "  \n",
    "  Vw.data -= learning_rate * Vw.grad.data\n",
    "\n",
    "  Vw.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "z7vfBOcqAlBw"
   },
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(LogisticRegression, self).__init__()\n",
    "    self.linear = nn.Linear(in_features, out_features, False)\n",
    "\n",
    "  def forward(self, x):\n",
    "    y_pred = torch.sigmoid(self.linear(x))\n",
    "    return y_pred\n",
    "  \n",
    "  def backward(self):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sDU4t1n0BtN7",
    "outputId": "e116615d-32e1-4e51-b355-82f59fc78a03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(\n",
      "  (linear): Linear(in_features=3, out_features=1, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "loss_fn = nn.BCELoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MkUagm3qCBIU",
    "outputId": "ab832885-8872-4d46-b3f6-196e8c20fbfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:999 Loss:0.6393\n",
      "Epoch:1999 Loss:0.6134\n",
      "Epoch:2999 Loss:0.5958\n",
      "Epoch:3999 Loss:0.5833\n",
      "Epoch:4999 Loss:0.5741\n",
      "Epoch:5999 Loss:0.5670\n",
      "Epoch:6999 Loss:0.5612\n",
      "Epoch:7999 Loss:0.5565\n",
      "Epoch:8999 Loss:0.5523\n",
      "Epoch:9999 Loss:0.5486\n",
      "Epoch:10999 Loss:0.5452\n",
      "Epoch:11999 Loss:0.5421\n",
      "Epoch:12999 Loss:0.5392\n",
      "Epoch:13999 Loss:0.5364\n",
      "Epoch:14999 Loss:0.5338\n",
      "Epoch:15999 Loss:0.5312\n",
      "Epoch:16999 Loss:0.5288\n",
      "Epoch:17999 Loss:0.5265\n",
      "Epoch:18999 Loss:0.5243\n",
      "Epoch:19999 Loss:0.5221\n",
      "Epoch:20999 Loss:0.5200\n",
      "Epoch:21999 Loss:0.5180\n",
      "Epoch:22999 Loss:0.5160\n",
      "Epoch:23999 Loss:0.5141\n",
      "Epoch:24999 Loss:0.5123\n",
      "Epoch:25999 Loss:0.5105\n",
      "Epoch:26999 Loss:0.5088\n",
      "Epoch:27999 Loss:0.5071\n",
      "Epoch:28999 Loss:0.5055\n",
      "Epoch:29999 Loss:0.5040\n",
      "Epoch:30999 Loss:0.5025\n",
      "Epoch:31999 Loss:0.5010\n",
      "Epoch:32999 Loss:0.4996\n",
      "Epoch:33999 Loss:0.4982\n",
      "Epoch:34999 Loss:0.4968\n",
      "Epoch:35999 Loss:0.4955\n",
      "Epoch:36999 Loss:0.4943\n",
      "Epoch:37999 Loss:0.4930\n",
      "Epoch:38999 Loss:0.4918\n",
      "Epoch:39999 Loss:0.4907\n",
      "Epoch:40999 Loss:0.4895\n",
      "Epoch:41999 Loss:0.4884\n",
      "Epoch:42999 Loss:0.4874\n",
      "Epoch:43999 Loss:0.4863\n",
      "Epoch:44999 Loss:0.4853\n",
      "Epoch:45999 Loss:0.4843\n",
      "Epoch:46999 Loss:0.4834\n",
      "Epoch:47999 Loss:0.4825\n",
      "Epoch:48999 Loss:0.4816\n",
      "Epoch:49999 Loss:0.4807\n",
      "Epoch:50999 Loss:0.4798\n",
      "Epoch:51999 Loss:0.4790\n",
      "Epoch:52999 Loss:0.4782\n",
      "Epoch:53999 Loss:0.4774\n",
      "Epoch:54999 Loss:0.4766\n",
      "Epoch:55999 Loss:0.4759\n",
      "Epoch:56999 Loss:0.4751\n",
      "Epoch:57999 Loss:0.4744\n",
      "Epoch:58999 Loss:0.4737\n",
      "Epoch:59999 Loss:0.4730\n",
      "Epoch:60999 Loss:0.4724\n",
      "Epoch:61999 Loss:0.4717\n",
      "Epoch:62999 Loss:0.4711\n",
      "Epoch:63999 Loss:0.4705\n",
      "Epoch:64999 Loss:0.4699\n",
      "Epoch:65999 Loss:0.4693\n",
      "Epoch:66999 Loss:0.4687\n",
      "Epoch:67999 Loss:0.4682\n",
      "Epoch:68999 Loss:0.4676\n",
      "Epoch:69999 Loss:0.4671\n",
      "Epoch:70999 Loss:0.4666\n",
      "Epoch:71999 Loss:0.4661\n",
      "Epoch:72999 Loss:0.4656\n",
      "Epoch:73999 Loss:0.4651\n",
      "Epoch:74999 Loss:0.4646\n",
      "Epoch:75999 Loss:0.4641\n",
      "Epoch:76999 Loss:0.4637\n",
      "Epoch:77999 Loss:0.4632\n",
      "Epoch:78999 Loss:0.4628\n",
      "Epoch:79999 Loss:0.4624\n",
      "Epoch:80999 Loss:0.4620\n",
      "Epoch:81999 Loss:0.4616\n",
      "Epoch:82999 Loss:0.4612\n",
      "Epoch:83999 Loss:0.4608\n",
      "Epoch:84999 Loss:0.4604\n",
      "Epoch:85999 Loss:0.4600\n",
      "Epoch:86999 Loss:0.4597\n",
      "Epoch:87999 Loss:0.4593\n",
      "Epoch:88999 Loss:0.4590\n",
      "Epoch:89999 Loss:0.4586\n",
      "Epoch:90999 Loss:0.4583\n",
      "Epoch:91999 Loss:0.4580\n",
      "Epoch:92999 Loss:0.4577\n",
      "Epoch:93999 Loss:0.4574\n",
      "Epoch:94999 Loss:0.4570\n",
      "Epoch:95999 Loss:0.4567\n",
      "Epoch:96999 Loss:0.4565\n",
      "Epoch:97999 Loss:0.4562\n",
      "Epoch:98999 Loss:0.4559\n",
      "Epoch:99999 Loss:0.4556\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch_n*1000):\n",
    "  y_pred = model(Vx)\n",
    "  loss = loss_fn(y_pred, Vy)\n",
    "  if (epoch + 1)%1000 == 0:\n",
    "    print('Epoch:{} Loss:{:.4f}'.format(epoch, loss))\n",
    "\n",
    "  model.zero_grad()\n",
    "  loss.backward()\n",
    "\n",
    "  for parameter in model.parameters():\n",
    "    parameter.data -= learning_rate * parameter.grad.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OVd1YVSoCuz0",
    "outputId": "1011eb19-d99f-402e-ba7c-02682d1c409d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2681,  3.4814, -2.1215]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.parameters():\n",
    "  print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "EC5oSriUCzCq"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "optimizer = opt.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "czAPfOaWDIDB",
    "outputId": "d6097834-59a8-4275-8524-494e2fa0add2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:999 Loss:0.6732\n",
      "Epoch:1999 Loss:0.6454\n",
      "Epoch:2999 Loss:0.6262\n",
      "Epoch:3999 Loss:0.6124\n",
      "Epoch:4999 Loss:0.6020\n",
      "Epoch:5999 Loss:0.5938\n",
      "Epoch:6999 Loss:0.5871\n",
      "Epoch:7999 Loss:0.5813\n",
      "Epoch:8999 Loss:0.5763\n",
      "Epoch:9999 Loss:0.5717\n",
      "Epoch:10999 Loss:0.5675\n",
      "Epoch:11999 Loss:0.5636\n",
      "Epoch:12999 Loss:0.5600\n",
      "Epoch:13999 Loss:0.5565\n",
      "Epoch:14999 Loss:0.5531\n",
      "Epoch:15999 Loss:0.5500\n",
      "Epoch:16999 Loss:0.5469\n",
      "Epoch:17999 Loss:0.5440\n",
      "Epoch:18999 Loss:0.5411\n",
      "Epoch:19999 Loss:0.5384\n",
      "Epoch:20999 Loss:0.5358\n",
      "Epoch:21999 Loss:0.5332\n",
      "Epoch:22999 Loss:0.5308\n",
      "Epoch:23999 Loss:0.5284\n",
      "Epoch:24999 Loss:0.5261\n",
      "Epoch:25999 Loss:0.5239\n",
      "Epoch:26999 Loss:0.5217\n",
      "Epoch:27999 Loss:0.5197\n",
      "Epoch:28999 Loss:0.5177\n",
      "Epoch:29999 Loss:0.5157\n",
      "Epoch:30999 Loss:0.5138\n",
      "Epoch:31999 Loss:0.5120\n",
      "Epoch:32999 Loss:0.5103\n",
      "Epoch:33999 Loss:0.5085\n",
      "Epoch:34999 Loss:0.5069\n",
      "Epoch:35999 Loss:0.5053\n",
      "Epoch:36999 Loss:0.5037\n",
      "Epoch:37999 Loss:0.5022\n",
      "Epoch:38999 Loss:0.5008\n",
      "Epoch:39999 Loss:0.4993\n",
      "Epoch:40999 Loss:0.4980\n",
      "Epoch:41999 Loss:0.4966\n",
      "Epoch:42999 Loss:0.4953\n",
      "Epoch:43999 Loss:0.4941\n",
      "Epoch:44999 Loss:0.4928\n",
      "Epoch:45999 Loss:0.4916\n",
      "Epoch:46999 Loss:0.4905\n",
      "Epoch:47999 Loss:0.4894\n",
      "Epoch:48999 Loss:0.4883\n",
      "Epoch:49999 Loss:0.4872\n",
      "Epoch:50999 Loss:0.4862\n",
      "Epoch:51999 Loss:0.4852\n",
      "Epoch:52999 Loss:0.4842\n",
      "Epoch:53999 Loss:0.4832\n",
      "Epoch:54999 Loss:0.4823\n",
      "Epoch:55999 Loss:0.4814\n",
      "Epoch:56999 Loss:0.4805\n",
      "Epoch:57999 Loss:0.4797\n",
      "Epoch:58999 Loss:0.4788\n",
      "Epoch:59999 Loss:0.4780\n",
      "Epoch:60999 Loss:0.4772\n",
      "Epoch:61999 Loss:0.4765\n",
      "Epoch:62999 Loss:0.4757\n",
      "Epoch:63999 Loss:0.4750\n",
      "Epoch:64999 Loss:0.4743\n",
      "Epoch:65999 Loss:0.4736\n",
      "Epoch:66999 Loss:0.4729\n",
      "Epoch:67999 Loss:0.4723\n",
      "Epoch:68999 Loss:0.4716\n",
      "Epoch:69999 Loss:0.4710\n",
      "Epoch:70999 Loss:0.4704\n",
      "Epoch:71999 Loss:0.4698\n",
      "Epoch:72999 Loss:0.4692\n",
      "Epoch:73999 Loss:0.4686\n",
      "Epoch:74999 Loss:0.4681\n",
      "Epoch:75999 Loss:0.4675\n",
      "Epoch:76999 Loss:0.4670\n",
      "Epoch:77999 Loss:0.4665\n",
      "Epoch:78999 Loss:0.4660\n",
      "Epoch:79999 Loss:0.4655\n",
      "Epoch:80999 Loss:0.4650\n",
      "Epoch:81999 Loss:0.4645\n",
      "Epoch:82999 Loss:0.4641\n",
      "Epoch:83999 Loss:0.4636\n",
      "Epoch:84999 Loss:0.4632\n",
      "Epoch:85999 Loss:0.4627\n",
      "Epoch:86999 Loss:0.4623\n",
      "Epoch:87999 Loss:0.4619\n",
      "Epoch:88999 Loss:0.4615\n",
      "Epoch:89999 Loss:0.4611\n",
      "Epoch:90999 Loss:0.4607\n",
      "Epoch:91999 Loss:0.4603\n",
      "Epoch:92999 Loss:0.4600\n",
      "Epoch:93999 Loss:0.4596\n",
      "Epoch:94999 Loss:0.4593\n",
      "Epoch:95999 Loss:0.4589\n",
      "Epoch:96999 Loss:0.4586\n",
      "Epoch:97999 Loss:0.4582\n",
      "Epoch:98999 Loss:0.4579\n",
      "Epoch:99999 Loss:0.4576\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch_n*1000):\n",
    "  y_pred = model(Vx)\n",
    "  loss = loss_fn(y_pred, Vy)\n",
    "  if (epoch + 1)%1000 == 0:\n",
    "    print('Epoch:{} Loss:{:.4f}'.format(epoch, loss))\n",
    "\n",
    "  model.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l41IXLhRDURv",
    "outputId": "4e270bf3-1328-4320-fc6b-e7335619e8f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2713,  3.3899, -2.0494]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.parameters():\n",
    "  print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VbP0E_eEDYOl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "02 build simple model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
